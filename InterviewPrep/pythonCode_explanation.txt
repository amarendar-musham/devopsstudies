Modules used: os,re; json,requests,csv/pandas,concurrent.futures, logging
Flask: {app|route|def} --> app = Flask(__name__), @app.route("/app"), def home(): return "Welcome"

-----
python modules:: importing modules.... 
	import requests, re, json, logging, threading, pandas
	from datetime import datetime ## print(datetime.now()) Used in scripts, time_took. 

	os.cpu_count(), os.getcwd(), os.path.getmtime(file) ## filemoddate in seconds
	csv, ## writer=csv.writer(file) ## writer.writerow([val1,val2,val3])
	selenium/webdriver  # driver = webdriver.Firefox() ## get method

import requests,json
### headers must have content-type when posting....
headers = { 'Content-Type': 'application/json', 'Authentication-Token' : open("base64-file","r").read().replace("\n","") }

response = requests.get('api_url', auth=('user', 'pass')) ## HTTPBasicAuth
response = requests.post(post_url, headers=headers, data=json.dumps(record)) ## (data)|json = payload 
if response.status_code != 200:	break ## else: continue
json_data = json.loads(response.text) ## (or)
with open(file,'w') as f: f.write(response.content) # json_data = json.load(f)
Note: (loads=stores data as json ; dumps=stores data as string) loads|dumps => string-data-type

## read records/rows in json content. ls = [] (or) list of dictionaries using comprehension
for row in json_data: ls.append(row["col1"]) ## return sorted(ls) (or)
ls = [{k:v for k,v in rec if k in selected_fields} for rec in json_data["data"]["items"]]  ## selected_fields = ["field1","f2"]

cmd = ['ls', '-ltr']
output_in_list = subprocess.run(" ".join(cmd), shell=True, capture_output=True, text=True).stdout.strip().split("\n")

Program - Syntax::
--------START
import statements....
global var1 = 'ex1'
class Issue:
	global var1
	var1 = 'ex1-update'
	var2 = 'ex2'
	def __init__(): # default function, exec when the class called. 
		.....
	keyvalueblocks = {   ## Dictionary defination
		'key1':"value1", 
		'key2':"value2",
	}
	def printsomet(self, a, b):
		x = ''
		...
		return x
class Ex2: ...

if __name__ == "__main__":
	 issue=Issue(json=bug_json) ## create object 
	 issue.printsomet(a, b) ## calling the method from Issue class. 
END--------

.........................................................
------Read input and search pattern ----------START
link = input("Give the main URL : ") ## read URL
pattern = input("Any filter : ").    ## read search item
print("{} with filter - {}".format(link,pattern), end="\n\n\n")

1. X = open('hi.txt', 'r')		## X is a file.
2. X = ['.....', '.....', '.....']	## X is a list. 
for line in X:
        if re.search(pattern, line):  ## similar to grep in Bash...
            print(line, end="")
END-------------
.........................................................

------ Write to a file --------START
f = open(file, mode); "f.write() followed by f.close()" ## method 1. 

with open('readme.txt', 'w') as f: ## method 2. 
    f.write('readme' + '\n')
    
var1 = sys.stdout
sys.stdout = f			## method 3. 
## run some method that prints output to stdout
## it will write stdout to file f.
sys.stdout = var1  ## after the work is done, reset the stdout. 
END---------
.........................................................


.........................................................
z = ['apple', 'banana', 'cherry'] ## print(list(enumerate(z)) ## for i, item in enumerate(z): print("{}-{}".format(i,item))

List of chars in String ==> for char in word: ls.append(char) ## "ls" is an array of chars...
String operations ==> for i in range(len(word)): if word[i] == word[i-1]: print("dups-near")
Reverse an array of string or sentence ==> s = "I like this program very much"; " ".join(s.split(" ")[::-1]) ## much very program this like i
Note: [::-1] reverses an array, string is array of chars ##  "amar"[::-1] == "rama" 
Palindrome check: if s == s[::-1]: True
Number of vowels in a given string = len([1 for char in s if char in vo]) (or) sum(1 for char in s if char in vo) ; vo="aeiouAEIOU" ; 


print(f.read()) ## similar to cat in Bash. 
print("The value of var1 is " + var1 + "\n") ## Output: The value of var1 is 10 //new line

ls = "one, two, three".split(", ") # list gets created with split. 
ls = url.split("/")[-1].split("_")[1:3] ### string = "_".join(ls) 
ls = file.readlines() ## create a list with lines in a file, note: includes - "\n"

ls = [x**2 for x in range(10) if x**2 % 2 == 0] #[0, 4, 16, 35, 64] ## list comprehensions
dict = { k: v.replace("prod","dev") for k,v in dict.items() } ## dictionary comprehensions
list_n_dict(jsonArray) = [ {k:v for k,v in x.items() if k in required_data_set } for x in json_data ] ## json_data is a JSON array
 	--> break_down = [x for x in json_data] + {k:v for k,v in dict.items()} 

str="{c},{b},{a}".format(a=5,b=9,c=7) ## 7,9,5 ## named args. 
str="{0}{1}{0}".format("abra","cad") ## abracadabra..

nums = [11, 22, 33, 44, 55]
result = list(map(lambda x: x+5, nums)) # [16,27,38,49,60]
res = list(filter(lambda x: x%2==0, nums)) # [22,44]

## (lambda-func: return-value) (func-args)
print((lambda x: x**2 + 5*x + 4) (-4))
add = lambda x,y: x+y ;; print(add(3,4)) ## lambda func in a variable.
ls = list(map(lambda x:x[:4].upper(), ls)) ## map passes arg(lx[x]) to lambda function, whereas x=0,1,2,3...

a = [1,2,3,5,6] ; b = [3,5,0] ; c = list(set(a)-set(b)) ## [1, 2, 6]

COLLECTION TYPES::
Tuples, lists can be unpacked(a,b,c=nums; a,b,*c,d=nums) *c takes leftover elements
Sets, dictionaries. # sets = no_duplicates, can give &(matched) |(all) -(substract) ^(unmatched) elements b/w two sets
# if 3 in nums: # gives True; similarly: key in dict ## alt: not in

def func(x, *args, *kwargs): ## *args are optional,
---- print(args) # (2,3,4) = tuple 
---- print(kwargs)# {'a':7,'b':8} = dictionary - keywordArg.
func(1,2,3,4,a=7,b=8) 
func(1)

---import re; metacharacters...
^$.| - start, end, anything, or ## () - group, [] - character class(match either of them inside it), [^a-z] - invert # anything other than a-z
{} - number of iteration in b/w
* - {0,} // + - {1,} // ? - {0,1} - zero or one

pattern = re.compile("-dev|-test")
ls2 = [x for x in ls if pattern.search(x)]
pattern = r"(.)*[A-Z]+(.)*[0-9]+(.)*" ## atleast one uppercase&number
if re.search(pattern, password): print("pass created")
patternForIP = r"^([0-9]{1,3}\.){3}[0-9]{1,3}$" # 1.2.3.4 //- numbers b/w 1 & 3 with dot(escape) three times, numbers b/w 1 & 3 one time.   
special sequence: \1 = matches exp of group(1) # (abc|xyz)\1 = "abc" or "xyz" followed by the same thing. 
\d, \s, \w = digit, space, word chars ; \D, \S, \W = inverts(other than what they are..) 
## Ex: r"#\w+" = re.findall(pattern, text) gives all hashtags. 

patternForEmail = r"([\w\.]+)@([\w\.]+)\.([\w\.]+)" # info@example.com
## basic = "()@()\.()" # these groups can have (words/dots)one or more = [\w\.]+

json_data = json.loads(re.sub(pattern, "", response.text, count=1)) ## find&replace only first occurrence in the json. 
==========================================================================================================================

import logging
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, filename="app.log",filemode="w",
                    format="%(asctime)s - %(levelname)s - %(message)s")
logger.info("") ## (info|warning|error)
 
-========================================================================================================================

import pandas as pd
df = pd.read_csv(csv_file)
df = pd.DataFrame.from_dict(ips_map, orient='index').reset_index()

df.to_csv(file2,index=False) # creates a csvfile
f.write(df.to_html(index=False)) ## f is a html file
print(df.to_string()) ## expands all rows 

df = df.sort_volues(by=col1) ## 
merged_df = df.merge(x_df, on='id',how='left')

df.columns # print headers
df = df.drop(columns=columns) ## columns='col1' or columns = ['col1','col2']
df.drop(df[<indexes>].index,inplace=True) ## indexes = df[col1].isin(ls)
df.rename(columns={old_col:new_col})
df = df[df["col1"] == "val1"]
ls = df[col1].dropna().to_list()
df[col1].isna() <or> df[col1].notna() ## gives true or false, 
df[df[col1].notna()]['col1','col2','col3'] ## prints col2 and col3 only when col1 is not null

df.iloc[0] / df['col1'].iloc[0:10]
df["col1"] = df["col1"].apply(transform_col1) ## apply a function
df.loc[df["col1"] == 0, "host"] = df["json"].apply(extract_host) ## host = new column, condition based out of col1
df['fqdn'] = df.apply(lamdba x: f"{x['host']}.{x['domain']}" if pd.notna(x['host']) ## fqdn = <host>.<domain>..

df.groupby(['col1','col2']).size() ## similar to sql query for groupby...
agg_df = df.groupby("id").agg({'col1':list,'col2':list,'col3':first})   ## id,ls1,ls2,col3 ## aggregation w/ groupby id....
df = df.groupby("id")[["pvt_ip","pub_ip"]].apply(lambda x: x.to_dict(orient="records")).reset_index(name="json") ## id1,{pvt:ipX,pub:ipY} = json column

df['col3'] = df.apply(lambda x: {x['col1']: x['col2']}, axis=1) creating a json column from existing columns
agg_df = agg_df.apply(lambda x: {k:v for k,v in zip(x[col1],x[col2])}, axis=1)

response = requests.post(url, headers={'Content-Type':'application/json'}, data=df.to_json(orient="records")) ## post entire dataframe
--------------

Insert to DB from a csv file....... ## python3 -m pip install mysql-connector-python ## install with "--user <>" if any errors of file permissions
conn = mysql.connector.connect(host="<fqdn>",user="<>",passwd="<>",database="<>")
cursor = conn.cursor()
query_templ = "insert into tb1 (col1, col2, col3) values (%s, %s, %s)"
try:
	cursor.execute("update tb1 set col4 = 0 where id > 0;")
        for ind in df.index:
            values = "('{}','{}',{})".format(df["col1"][ind],df["col2"][ind],df["col3"][ind])
            cursor.execute(sql,eval(values))
            print(cursor.rowcount, "record inserted!")
        conn.commit()
except Exception as e:  
        print("failed to execute: {}".format(e))
        conn.rollback()
conn.close()
==========================================================================================================================

import concurrent.futures as cf
with cf.ThreadPoolExecutor(max_workers=os.cpu_count() * 2) as exec:
	results = exec.map(method, ls) ## method(arg), method iterates through out the list, every line as a arg.
if results: [res for res in results] ## results is a list of returned items from the method
if results: [ips_map.update(res) for res in results if res] ## res is a dict returned by the method

## exec.map(method, zip(ls1, ls2)) ## method(a,b) ==> method(ls1[x],ls2[x]) indexes will go parallel in each list
## exec.map(lambda args: method(*args),itertools.product(ls1,ls2)) ## itertools maps each item in a list with all items in the another list


with cf.ThreadPoolExecutor(max_workers=os.cpu_count() * 2) as exec: ## results =[]
	futures =[]
	for args in args_iterable:
		futures.append(executor.submit(target_func, *args))
	for future in cf.as_completed(futures):
            results.append(future.result())
return results

ls = [line.replace("\n","") for line in file]
 
==========================================================================================================================

from flask import Flask, render_template, jsonify, send_file, request, flash

app = Flask(__name__)
@app.route("/app")
def home():
	return render_template("temp.html", tables=[df.to_html(index=False)], titles=[''], t_mod = filemodtime)
	
@app.route("/app/run", methods=["GET","POST"])
def run():
	arg1 = request.args.get('arg1')
	if not arg1:
        	return jsonify({"Error": "Arguement 'job' is expected"})
	else:
		eval("py_module.run_" + arg1 + "()")
		.....return statement.....
		
@app.route("/app.json")
def json():
	csvReader = csv.DictReader(open("csv_file","w"))	
	for row in csvReader:
		ls.append(row)
	return jsonify(ls)

@app.route("/download/<file>")
def download(file):
    path = "{}/{}".format(os.getcwd(),str(file))
    return send_file(path, as_attachment=True)
    
@app.route("/api")
def list_routes():
    return ['%s' % rule for rule in app.url_map.iter_rules()]
    
if __name__ == '__main__':
    app.secret_key = 'super secret key'
    app.config['SESSION_TYPE'] = 'filesystem'
    app.run(host='0.0.0.0', port=5050,debug=True)
    
==========================================================================================================================
<table>
	{% for table in tables %}
	<h2>{{titles[loop.index]}}</h2>
	{{table | safe}} 
	{% endfor %}
</table> 
==========================================================================================================================
