Syntax:
create table <tb> (col1 datatype(length),...) 
alter table <tb> add|modify col1 varchar2(250) ## add constraint <> primary key (col1)

insert into table1 (col1, col2, col3, col4) values ('string1','string2',100,10.0); 
delete from table1 where example_recent > 0; ## clears data of recent update
update table1 set col1 = val1, col2=val2 where col3 > VAL; ## set recent=0 for all existing data

join-[ON]:                select ... from <table> a JOIN <table> b ON a.<> = b.<>
case-when-[else]-end:     case when <cond> then "output" else "" end ## used for new columns, order by
regexp_like:              regexp_like(col1, pattern) ## used in Where (or) Case-When conditions

new-column: select p.*, <col1> from <table> p
replace: replace(type,'good_','bad_')  ## new columns 
min|max|avg: avg(<col1>) ## used for new columns
listagg: listagg(subject || '-' || marks, '/') within group(order by subject) ## used for new columns
percentile_cont: percentile_cont(0.75) within group(order by diff asc) over (partition by type,job) ## used for new column = 75%(diff)
		## this gives a 75th value in the list of {1..100}

imaginary table: with tb1 as (<query1>), tb2 as (<query2>)  ## used futher in actual query. 

json_table: json_table(p.jsoncol, '$[*]' columns(col1 datatype(length) path '$.col1',....) )
	usage: select p.*,min(j.col1) from table p, json_table(..) as j 
            ## To give jsonArray objects in single row, then use min/max/avg (or) for multiple rows, use [group by p.<>,j.col1]
            ## ex: select p.type,j.job, min(j.start),max(j.end),(end-start) as diff ....... group by p.type,j.job => 
-----------------------------------------
join-on types: https://www.w3schools.com/sql/sql_join.asp
	Left join: Returns all-rows(left) + matching rows(right) ## Right join X Left join
	Inner join: Combines tables on matching values in a specified column
	Full outer join: Returns all-rows(both), as long as there is at least one match
	Cross join: Returns every combination of each-row from table1 with each-row from table2
		## ex: select t.type,s.status from Types t cross join Status s 
	
	Self join: Joins a table to itself, allowing for comparison of rows within the same table
		## ex: select a.<>,b.<> from table1 a, table1 b where a.<> = b.<>
	Natural join: Joins tables based on a common column
=====================================================================

$ vim /etc/yum.repos.d/example.repo
## set, (enabled=1) for <os-version>_appstream repo. 

$ yum search mysql ; yum install mysql-server

$ mysql -u root -p ## default no-passwd

Create User.... and resp queries....==============
CREATE USER 'amar'@'localhost' IDENTIFIED BY 'Welcome123!'; ## create/alter(passwd), localhost/fqdn/%(wildcard)=anyhost/
RENAME USER 'amar'@'localhost' TO 'amar'@'%';
GRANT ALL PRIVILEGES ON *.* TO 'amar'@'%' WITH GRANT OPTION; ## localhost/fqdn
FLUSH PRIVILEGES; ## reload grant tables...
========================================================

$ mysql> show databases ;
$ mysql> use abcd ; ## abcd database schema
$ mysql> show tables ;
$ mysql> select * from table1 ; select * from table1 FETCH FIRST 5 ROWS ONLY ## top 5 rows
$ mysql> desc table1 ; # shows the table structure
$ mysql> show create table table1 ## prints sql query that used to create the table table1
$ mysql> source example.sql ; # run sql queries script

create-table.sql==================================
create table "example" ## alt: reg_id int auto_increment,
( "reg_id" number generated always AS identity minvalue 1 maxvalue 9999999999999999999999999999 increment by 1 start with 1 cache 20 noorder nocycle nokeep noscale not null enable,
    "email" varchar2(100), 
    "phone" varchar2(15), 
    "gender" varchar2(10), 
    "reg_date" date default sysdate, 
    primary key ("reg_id") );
-----
create table photo_tb
(   "photono" int auto_increment,
    "image" blob, 
    "mimetype" varchar2(255 CHAR), 
    "imagename" varchar2(400 CHAR), 
    "image_last_update" date, 
     constraint "photo_tb_PK" primary key ("photono")
  using index  enable
) ; ========================================================

==> input data types allowed = application/json
From Apex:::
source for GET api <endpoint>/get/:key==> select * from ExampleTable where KEY=:key
pl/sql for POST api <endpoint>/insert ==> begin insert into tb1 (col1, col2, col3) VALUES (:col1, :col2, :col3) ; end;
pl/sql for PUT api <endpoint>/update/:key ==> begin update tb1 set col1 = :col1, col2 = :col2, col3 = :col3 where KEY = :key; end; 

==> If a filter value is null choose all records
Ex: Null display value = ALL, Null return value = %
==> field LIKE :var || %

========================================================
example queries with join statement....

SELECT a.stock_code FROM price_today a
INNER JOIN price_tomorrow b ON a.stock_code = b.stock_code
WHERE b.price > a.price ORDER BY stock_code asc;

SELECT ei.employee_ID, ei.name FROM employee_information ei
JOIN last_quarter_bonus b ON b.employee_ID = ei.employee_ID
WHERE ei.division LIKE 'HR' AND b.bonus >= 5000;

select cs.customer_name, cast(iv.total_price as decimal(12,6)) from customer cs
join invoice iv on iv.customer_id = cs.id
where iv.total_price < 588.375 order by iv.total_price desc;

## multiple join...
select ct.city_name, pd.product_name, round(iv.total_price,2) from city ct
join customer cs on cs.city_id = ct.id
join invoice iv on cs.id = iv.customer_id
join invoice_item ivt on iv.id = ivt.invoice_id
join product pd on ivt.product_id = pd.id
order by iv.total_price desc, ct.city_name asc, pd.product_name asc;

============= Group By and Order By example =============
select count(*), to_char(created,'MONYYYY') from ExampleTable 
group by to_char(created,'MONYYYY')
order by to_date(to_char(created,'MONYYYY'),'MMYYYY')

TO_DATE:
    select * from ExampleTable where created >= to_date('3/1/2024','mm/dd/yyyy') ## created can be timezone(6)
    Note: to_char(created, 'mm/dd/yyyy') <= <some_date> ## Must convert the "created" field for less than a date. 

select * from ExampleSchema.ExampleTable ## skip condition if variable not passed
where ( :start_date is NULL or created >= to_date(:start_date, 'dd-mm-yyyy') )
and ( :end_date is NULL or created < to_date(:end_date, 'dd-mm-yyyy') + 1 )
order by created desc

============== Get Unique records of a specific column ============
select distinct <col1> from ExampleTable ## Ex: col1=city_name

============= To filter recs with null values ================
select nvl(col1,0) as field from ExampleTable where field=nvl(:var1,0) ## var1 can be a variable in apex for example.

============== case-when examples ============
select count(case when field='True' then 1 else null end) from ExampleTable ##Get a count with condition
select col1,col2, case when col1='val1' then 'red' else 'green' end as COLORS from ExampleTable # create new column=colors
    select type, status,
    case when status = 'SUCCESS' then (count - (select count from HLG where type=t.type and status='HEALED')) else count end as count,
    from hlg t order by type,status desc

select id, type, case when regexp_like(status, 'FAILED|IN_PROGRESS|TIMEOUT') then 'FAILED' else status from ExampleTable

select id,type,status from tb1 ORDER BY case when type='..' then 0 when type='..' then 1 end

select et.*, (case when type='..' then 'typeX' else type end) as mod_type from ExampleTable et ## create a new column

===============Regex usage for where/case-when condition===============
simple pattern matching::
    select * from ExampleTable where type LIKE '%_morning%'
regex pattern matching::
    select * from ExampleTable where REGEXP_LIKE(type,'good_(morning|night)') ## regex pattern in type column
    select * from ExampleTable where regexp_like('good_morning,good_night',type) ## to search multiple values
## Can be used >> case when regexp_like(...) then '...' end as col<3>

===============imaginary table use in a query============
Ex1: with tb as ( select * from XX; union all ; select * from YY) ## further used as <select * from tb>
Ex2: with tb1 as (select * from XX), tb2 as (select * from YY) ## further used as two separate tables: tb1, tb2

===============Fill the gaps with zeros(Cross-Join + COALESCE)============  ## use above imaginary table 
## coalesce(multi-args) ~ nvl(only 2args), gives first non-null value

select Types.type, Statuses.status, coalesce(your_table.count,0) 
from (select distinct type from your_table) Types
cross join (select distinct status from your_table) Statuses
left join your_table on Types.type=your_table.type and Statuses.status=your_table.status
### ex: type: prov|upg|patch, status: success|failed|healed

ListAggregation:
select name, sum(marks), listagg(subject || '-' || marks, '/') within group(order by subject) from tb1 group by name 
Result: Amar 100 maths-50/science-50 ## input: 1)Amar maths 50, 2)Amar science 50

=============== Replace method usage ===============
select replace(type,'good_','bad_') from ExampleTable ## syntax: replace(column, string, to_replace_with)

=====================Alter Table================================
alter table ExampleTable ADD column_name <data_type>; ## data_type.Ex: varcar2(50) 
alter table ExampleTable ADD primary key (col_name); 
alter table <schema>.<tb1> add constraint <name> primary key ("col1");
alter table <schema>.<tb1> add constraint <name> foreign key ("col1") references <tb2> ("col2");
alter table SCH1.tb1 add col1 varchar2(4000) check (col1 is null or col1 is JSON) ## <add|modify> ## json constraint

JSON_TABLE:================================
select t.*, j.col1, j.col2 from tb1 t, json_table(t.jsoncol, $[*] columns (...)) as j ## jsoncol = jsonArray(array of json objects)
Ex: select t.type, j.JOB, min(j.START), max(j.END), (:E - :S)*24 as diff ## ":E|:S" = to_date(max(END),'..format..')
from tb1 t, JSON_TABLE(t.jsoncol, $[*] columns (
    JOB varchar2(50) path '$.job',
    START varchar2(50) path '$.start',
    END varchar2(50) path '$.end'
)) as j group by t.type, j.job

Get 75% avg of diff: 
select type, job, avg(case when diff <= 75_val then diff end) as AVG_75 from 
(select tb1.*, percentile_cont(0.75) within group(order by diff asc) over (partition by type,job) as 75p_cutVal from tb1)
group by type, job
================================================================

Calculate Size of a Table ==> select segment_name, bytes/(1024*1024) from user_segments where segment_name in (select table_name from user_tables)

================================================================
Data definition language (DDL) describes the portion of SQL that creates, alters, and deletes database objects

select dbms_metadata.get_ddl('TABLE', '<table_name>') from dual ## create table definition.
SELECT dbms_metadata.get_ddl('INDEX', index_name) from all_indexes where table_name = <tb1> ## create index definition











